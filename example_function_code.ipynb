{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file has code for help getting started creating a function which generate clues considering the entire board (opponents' words + assassin words + \"bystander\" words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import gensim\n",
    "import re\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import FastText\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.cluster import KMeans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in the cleaned dictionary\n",
    "df = pd.read_csv('cleaned_dict.csv')\n",
    "\n",
    "#replace commas with spaces\n",
    "df['definition'] = df['definition'].str.replace(',', ' ')\n",
    "#remove any non-alphabetic characters\n",
    "df['definition'] = df['definition'].str.replace('[^a-zA-Z]', '')\n",
    "\n",
    "#tokenize the definitions\n",
    "df['definition'] = df['definition'].apply(word_tokenize)\n",
    "#remove quotes from the words\n",
    "df['definition'] = df['definition'].apply(lambda x: [word.replace(\"'\", \"\") for word in x])\n",
    "\n",
    "#train the word2vec model\n",
    "model = Word2Vec(df['definition'], min_count=5, window=5, sg=0)\n",
    "\n",
    "#save the model\n",
    "model.save('codenames.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a function that generates clues ONLY for our words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_word_clusters_clues(words_input, model, df, n_clustersIn):\n",
    "    # Extract word vectors and normalize them\n",
    "    vectors = [model.wv[word] for word in words_input]\n",
    "    normalized_vectors = normalize(vectors)\n",
    "\n",
    "    # Initialize k-means model and fit it to the normalized vectors\n",
    "    kmeans = KMeans(n_clusters=n_clustersIn, random_state=100)\n",
    "    kmeans.fit(normalized_vectors)\n",
    "\n",
    "    # Get cluster assignments for each word\n",
    "    cluster_assignments = kmeans.predict(normalized_vectors)\n",
    "\n",
    "    # Create a dataframe using Pandas library with the clusters of words as rows in lists\n",
    "    clues_df = pd.DataFrame({'words': words_input, 'cluster': cluster_assignments})\n",
    "    clues_df = clues_df.groupby('cluster')['words'].apply(list).reset_index()\n",
    "\n",
    "    # Add columns to keep track of the most similar word and its similarity score -- so we can use it as a clue\n",
    "    clues_df['maxSimilarity'] = 0.0\n",
    "    clues_df['mostSimilarWord'] = ''\n",
    "\n",
    "    # Loop to generate clues for each cluster\n",
    "    # Iterate throw every row in the dataframe\n",
    "    for index, row in clues_df.iterrows():\n",
    "        # Get the cluster words and calculate the cluster center\n",
    "        cluster_words = row['words']\n",
    "        cluster_center = np.mean([model.wv[word] for word in cluster_words], axis=0)\n",
    "\n",
    "        # Get the most similar words and their similarity scores\n",
    "        most_similar_words = model.wv.most_similar([cluster_center], topn=len(words_input) * 2)\n",
    "        # Filter out words that are already in the clusters -- we CANNOT use them as clues\n",
    "        most_similar_words = [(word, score) for word, score in most_similar_words if word not in cluster_words]\n",
    "        \n",
    "        # first word is most similar word\n",
    "        most_similar_word, similarity_score = most_similar_words[0]\n",
    "        # Set maxSimilarity and mostSimilarWord for the clusters; add to dataframe\n",
    "        clues_df.at[index, 'maxSimilarity'] = similarity_score\n",
    "        clues_df.at[index, 'mostSimilarWord'] = most_similar_word\n",
    "\n",
    "    # Return the dataframe with the clusters and their clues\n",
    "    return clues_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume we are the starting team, so we have 9 words\n",
    "word_list = ['battery', 'beach', 'church', 'ham', 'lawyer', 'marble', 'night', 'michigan', 'horse']\n",
    "\n",
    "# Use our function to generate clues, we'll set the number of clusters to 5\n",
    "clues_dataframe = generate_word_clusters_clues(word_list, model, df, n_clustersIn=5)\n",
    "\n",
    "# Print the generated data frame which contains the clusters, their clues (mostSimilarWord), and the similarity score\n",
    "print(clues_dataframe)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we give out the clue and associated number of words it corresponds to (like we would when playing the game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the row with the highest similarity score and print the clue (most similar word, number)\n",
    "max_similarity_row = clues_dataframe.loc[clues_dataframe['maxSimilarity'].idxmax()]\n",
    "print(f\"{max_similarity_row['mostSimilarWord']} {len(max_similarity_row['words'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we should modify our function to consider the entire board.\n",
    "NOTE: this is just one way of implementing this. Feel free to experiment with other methods. We use similarity score to check how \"good\" the clues are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_word_clusters_clues(words_input, model, df, opponents_words, assassin_word, n_clustersIn, threshold_similarity):\n",
    "    # Extract word vectors and normalize them\n",
    "    vectors = [model.wv[word] for word in words_input]\n",
    "    normalized_vectors = normalize(vectors)\n",
    "\n",
    "    # Initialize k-means model and fit it to the normalized vectors\n",
    "    kmeans = KMeans(n_clusters=n_clustersIn, random_state=10)\n",
    "    kmeans.fit(normalized_vectors)\n",
    "\n",
    "    # Get cluster assignments for each word\n",
    "    cluster_assignments = kmeans.predict(normalized_vectors)\n",
    "\n",
    "    # Create a dataframe using Pandas library with the clusters of words as rows in lists\n",
    "    clues_df = pd.DataFrame({'words': words_input, 'cluster': cluster_assignments})\n",
    "    clues_df = clues_df.groupby('cluster')['words'].apply(list).reset_index()\n",
    "\n",
    "    # Add columns to keep track of the most similar word and its similarity score -- so we can use it as a clue\n",
    "    clues_df['maxSimilarity'] = 0.0\n",
    "    clues_df['mostSimilarWord'] = ''\n",
    "\n",
    "    # Loop to generate clues for each cluster\n",
    "    # Iterate throw every row in the dataframe\n",
    "    for index, row in clues_df.iterrows():\n",
    "        # Get the cluster words and calculate the cluster center\n",
    "        cluster_words = row['words']\n",
    "        cluster_center = np.mean([model.wv[word] for word in cluster_words], axis=0)\n",
    "\n",
    "        # Get the most similar words and their similarity scores\n",
    "        most_similar_words = model.wv.most_similar([cluster_center], topn=len(words_input) * 2)\n",
    "        # Filter out words that are already in the clusters -- we CANNOT use them as clues\n",
    "        most_similar_words = [(word, score) for word, score in most_similar_words if word not in cluster_words]\n",
    "\n",
    "        # TODO: Filter out clues too similar to bad words or the assassin word\n",
    "        filtered_similar_words = []\n",
    "        for word, score in most_similar_words:\n",
    "            # IDEA: Use the similarity score to filter out words that are too similar to opponents words or the assassin word\n",
    "\n",
    "        # Check if there are still potential clues after filtering\n",
    "        if filtered_similar_words:\n",
    "            # First word is most similar word\n",
    "            most_similar_word, similarity_score = filtered_similar_words[0]\n",
    "            # Set maxSimilarity and mostSimilarWord for the clusters; add to dataframe\n",
    "            clues_df.at[index, 'maxSimilarity'] = similarity_score\n",
    "            clues_df.at[index, 'mostSimilarWord'] = most_similar_word\n",
    "\n",
    "    return clues_df\n",
    "\n",
    "def get_best_clues(clues_dataframe):\n",
    "    # Find the best clue from the available options\n",
    "    max_similarity_row = clues_dataframe.loc[clues_dataframe['maxSimilarity'].idxmax()]\n",
    "    best_clue_word = max_similarity_row['mostSimilarWord']\n",
    "    cluster_words = max_similarity_row['words']\n",
    "    return best_clue_word, len(cluster_words), cluster_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This in an example for how we can use the function. Experiment with different words and assasin word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the scenario\n",
    "word_list = ['battery', 'beach', 'church', 'ham', 'lawyer', 'marble', 'night', 'michigan', 'horse']\n",
    "opponents_words = ['angel', 'bottle', 'diamond', 'glove', 'needle', 'temple', 'pound', 'stream']  # Add your list of bad words\n",
    "assassin_word = 'assassin'\n",
    "threshold_similarity = 0.8  # Adjust the threshold based on how \"aggressive\" you want the clues to be\n",
    "n_clusters = 5  # Adjust the number of clusters if needed\n",
    "\n",
    "# Generate clues\n",
    "clues_dataframe = generate_word_clusters_clues(word_list, model, df, bad_words, assassin_word, n_clusters, threshold_similarity)\n",
    "\n",
    "# Get the best clue\n",
    "best_clue = get_best_clues(clues_dataframe)\n",
    "\n",
    "best_clue_word, num_words, associated_words = best_clue\n",
    "print(f\"Best Clue: {best_clue_word} {num_words}\")\n",
    "print(\"Associated Words:\")\n",
    "for word in associated_words:\n",
    "    similarity_score = model.wv.similarity(best_clue_word, word)\n",
    "    print(f\"{word}: {similarity_score}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
