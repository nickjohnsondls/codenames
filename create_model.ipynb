{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#load the cleaned_dict.csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import gensim\n",
    "import re\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import FastText\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "\n",
    "df = pd.read_csv('cleaned_dict.csv')\n",
    "\n",
    "#replace commas with spaces\n",
    "df['definition'] = df['definition'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "#train a word2vec model on the definitions column\n",
    "\n",
    "#train a word2vec model on the definitions column\n",
    "sentences = [word_tokenize(x) for x in df['definition']]\n",
    "model = Word2Vec(sentences,window=10, min_count=1, workers=4)\n",
    "model.save('codenames.model')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv445",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
